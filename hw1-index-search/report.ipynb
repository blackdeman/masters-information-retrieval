{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отчет по лабороторной работе №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала привожу листинг с некоторыми комментариями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "from itertools import groupby\n",
    "from itertools import chain\n",
    "from operator import itemgetter\n",
    "from numpy import arange\n",
    "\n",
    "import nltk\n",
    "from nltk import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "default_tokenize_func = word_tokenize\n",
    "default_lemmatizer = None # WordNetLemmatizer()\n",
    "default_stemmer = SnowballStemmer(\"english\")\n",
    "default_stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# код из eval.py, завернутый в функцию\n",
    "def eval_metrics(groundtruth_file, answer_file):\n",
    "    q2reld = {}\n",
    "    for line in open(groundtruth_file):\n",
    "        qid, did = [int(x) for x in line.split()]\n",
    "        if qid in q2reld.keys():\n",
    "            q2reld[qid].add(did)\n",
    "        else:\n",
    "            q2reld[qid] = set()\n",
    "\n",
    "    q2retrd = {}\n",
    "    for line in open(answer_file):\n",
    "        qid, did = [int(x) for x in line.split()]\n",
    "        if qid in q2retrd.keys():\n",
    "            q2retrd[qid].append(did)\n",
    "        else:\n",
    "            q2retrd[qid] = []\n",
    "\n",
    "    N = len(q2retrd.keys())\n",
    "    precision = sum([len(q2reld[q].intersection(q2retrd[q])) * 1.0 / len(q2retrd[q]) for q in q2retrd.keys()]) / N\n",
    "    recall = sum([len(q2reld[q].intersection(q2retrd[q])) * 1.0 / len(q2reld[q]) for q in q2retrd.keys()]) / N\n",
    "    fmeasure = 2 * precision * recall / (precision + recall)\n",
    "    # print(\"mean precision: {}\\nmean recall: {}\\nmean F-measure: {}\" \\\n",
    "    #       .format(precision, recall, 2 * precision * recall / (precision + recall)))\n",
    "\n",
    "    # MAP@10\n",
    "    import numpy as np\n",
    "\n",
    "    MAP = 0.0\n",
    "    for q in q2retrd.keys():\n",
    "        n_results = min(10, len(q2retrd[q]))\n",
    "        avep = np.zeros(n_results)\n",
    "        for i in range(n_results):\n",
    "            avep[i:] += q2retrd[q][i] in q2reld[q]\n",
    "            avep[i] *= (q2retrd[q][i] in q2reld[q]) / (i + 1.0)\n",
    "        MAP += sum(avep) / min(n_results, len(q2reld[q]))\n",
    "    # print(\"MAP@10: {}\".format(MAP / N))\n",
    "    map10 = MAP / N\n",
    "\n",
    "    return precision, recall, fmeasure, map10\n",
    "\n",
    "# функция для парсинга файла\n",
    "# вырезает куски соответствующие определенной секции в файле и возвращает сам кусок и присвоенный ему идентификатор\n",
    "def parse_file(file, label='W'):\n",
    "    section_labels = {'I', 'T', 'A', 'B', 'W'}\n",
    "\n",
    "    section_found = False\n",
    "    id = 1\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "\n",
    "        document = ''\n",
    "\n",
    "        for line in f.readlines():\n",
    "\n",
    "            stipped_line = line.strip()\n",
    "\n",
    "            if len(stipped_line) == 0:\n",
    "                continue\n",
    "\n",
    "            if stipped_line.startswith('.' + label):\n",
    "                section_found = True\n",
    "            elif len(stipped_line) >= 2 and stipped_line[0] == '.' and stipped_line[1] in section_labels:\n",
    "                if section_found:\n",
    "                    yield (id, document.strip())\n",
    "                    document = ''\n",
    "                    id += 1\n",
    "                    section_found = False\n",
    "\n",
    "            elif section_found:\n",
    "                document += ' ' + stipped_line\n",
    "\n",
    "        if section_found:\n",
    "            yield (id, document.strip())\n",
    "\n",
    "# функция нормализации текста\n",
    "# бьет текст на токены, удаляет стоп-слова(если передан список слов), применяет лемматизатор и стеммер (переданы)\n",
    "# возвращает токен с его частотой\n",
    "def normalize_text(text,\n",
    "                   tokenize_func=default_tokenize_func,\n",
    "                   lemmatizer=default_lemmatizer,\n",
    "                   stemmer=default_stemmer,\n",
    "                   stop_words=default_stop_words):\n",
    "    tokens = list()\n",
    "\n",
    "    for token in tokenize_func(text):\n",
    "        if token in string.punctuation:\n",
    "            continue\n",
    "\n",
    "        if token in stop_words:\n",
    "            continue\n",
    "\n",
    "        if lemmatizer:\n",
    "            token = lemmatizer.lemmatize(token)\n",
    "\n",
    "        if stemmer:\n",
    "            token = stemmer.stem(token)\n",
    "\n",
    "        tokens.append(token)\n",
    "\n",
    "    tokens.sort()\n",
    "\n",
    "    return [(key, len(list(group))) for key, group in groupby(tokens)]\n",
    "\n",
    "# расчет RSV по заданным параметрам (соответствует пункту 3 в задании)\n",
    "def calc_rsv_default(N, Nt, ftd, ftq, Ld, L, b, k1, k2):\n",
    "    idf = calc_idf_default(N, Nt)\n",
    "    tf = ftd * (k1 + 1) / (k1 * ((1 - b) + b * Ld / L) + ftd)\n",
    "    return idf * tf\n",
    "\n",
    "# вспомогательная функция для расчета IDF\n",
    "def calc_idf_default(N, Nt):\n",
    "    return math.log(1 + (N - Nt + 0.5) / (Nt + 0.5))\n",
    "\n",
    "# инвертированный индекс с возможностью добавления документов по одному и поиску\n",
    "class InvertedIndex:\n",
    "    def __init__(self, lemmatizer=default_lemmatizer, stemmer=default_stemmer):\n",
    "        self.lemmatizer = lemmatizer\n",
    "        self.stemmer = stemmer\n",
    "        self.documents_total_length = 0\n",
    "        self.documents = dict()\n",
    "        self.index = defaultdict(list)\n",
    "\n",
    "        pass\n",
    "\n",
    "    # добавление документа\n",
    "    def add_document(self, doc_id, document):\n",
    "        self.documents_total_length += len(document)\n",
    "        self.documents[doc_id] = document\n",
    "\n",
    "        # todo maybe sort after add\n",
    "        for token in normalize_text(document, lemmatizer=self.lemmatizer, stemmer=self.stemmer):\n",
    "            self.index[token[0]].append((doc_id, token[1]))\n",
    "\n",
    "        pass\n",
    "\n",
    "    # поиск\n",
    "    def search_okapi_bm25(self, query, b, k1, k2, rsvfunc, norm_rsv, limit=10):\n",
    "        result = defaultdict(int)\n",
    "\n",
    "        N = len(self.documents)\n",
    "        L = self.documents_total_length / len(self.documents)\n",
    "\n",
    "        idf_sums = defaultdict(int)\n",
    "\n",
    "        for token_tuple in normalize_text(query, lemmatizer=self.lemmatizer, stemmer=self.stemmer):\n",
    "            ftq = token_tuple[1]\n",
    "            token_docs = self.index[token_tuple[0]]\n",
    "            Nt = len(token_docs)\n",
    "            for doc_tuple in token_docs:\n",
    "                doc_id = doc_tuple[0]\n",
    "                ftd = doc_tuple[1]\n",
    "                Ld = len(self.documents[doc_id])\n",
    "\n",
    "                result[doc_id] += rsvfunc(N, Nt, ftd, ftq, Ld, L, b, k1, k2)\n",
    "\n",
    "                if norm_rsv :\n",
    "                    idf_sums[doc_id] += calc_idf_default(N, Nt)\n",
    "\n",
    "        result = list(result.items())\n",
    "\n",
    "        if norm_rsv:\n",
    "            result = [(x[0], x[1] / idf_sums[x[0]]) for x in result]\n",
    "\n",
    "        result = sorted(result, key=itemgetter(1), reverse=True)\n",
    "        return [x[0] for x in result][:limit]\n",
    "\n",
    "    # размер словаря\n",
    "    def get_dist_size(self):\n",
    "        return len(self.index)\n",
    "    \n",
    "    # средняя длина posting-листа\n",
    "    def get_average_postings_list_length(self):\n",
    "        l = [len(p) for p in self.index.values()]\n",
    "        return sum(l) / len(l)\n",
    "\n",
    "    # максимальная длина posting-листа\n",
    "    def get_max_postings_list_length(self):\n",
    "        l = [len(p) for p in self.index.values()]\n",
    "        return max(l)\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        print(\"\\tStatistics:\\n\\tDictionary size = {}\\n\\tAverage postings list length = {}\\n\\tMax postings list length = {}\"\n",
    "              .format(self.get_dist_size(), self.get_average_postings_list_length(), self.get_max_postings_list_length()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним инвертированный индекс используя данные тексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# индекс по заголовкам (с использованием стеммера)\n",
    "indexTS = InvertedIndex()\n",
    "# индекс по заголовкам (с использованием лемматизатора)\n",
    "indexTL = InvertedIndex(lemmatizer=WordNetLemmatizer(), stemmer=None)\n",
    "# индекс по всему abstract (с использованием стеммера)\n",
    "indexWS = InvertedIndex()\n",
    "# индекс по всему abstract (с использованием лемматизатора)\n",
    "indexWL = InvertedIndex(lemmatizer=WordNetLemmatizer(), stemmer=None)\n",
    "for doc_tuple in parse_file('cran.all.1400', 'T'):\n",
    "    indexTS.add_document(doc_tuple[0], doc_tuple[1])\n",
    "    indexTL.add_document(doc_tuple[0], doc_tuple[1])\n",
    "for doc_tuple in parse_file('cran.all.1400', 'W'):\n",
    "    indexWS.add_document(doc_tuple[0], doc_tuple[1])\n",
    "    indexWL.add_document(doc_tuple[0], doc_tuple[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем поиск по каждому из индексов и рассчитаем показатели качества (вместе с этим, распечатаем статистику по каждому из индексов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_search_eval(index, b=0.75, k1=1.2, k2=None, rsvfunc=calc_rsv_default, norm_rsv=False):\n",
    "    with open('answer', 'w') as output:\n",
    "        for query_tuple in parse_file('cran.qry'):\n",
    "            query_id = query_tuple[0]\n",
    "            for doc_id in index.search_okapi_bm25(query_tuple[1], b=b, k1=k1, k2=k2, rsvfunc=rsvfunc, norm_rsv=norm_rsv):\n",
    "                output.write(\"{} {}\\n\".format(query_id, doc_id))\n",
    "\n",
    "    return eval_metrics('qrel_clean', 'answer')\n",
    "\n",
    "precision, recall, fmeasure, map10 = parse_search_eval(indexTS)\n",
    "print(\"Index For Titles (stemmer)\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))\n",
    "indexTS.print_statistics()\n",
    "\n",
    "precision, recall, fmeasure, map10 = parse_search_eval(indexTL)\n",
    "print(\"Index For Titles (lemmatizer)\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))\n",
    "indexTL.print_statistics()\n",
    "\n",
    "precision, recall, fmeasure, map10 = parse_search_eval(indexWS)\n",
    "print(\"Index For Abstracts (stemmer)\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))\n",
    "indexWS.print_statistics()\n",
    "\n",
    "precision, recall, fmeasure, map10 = parse_search_eval(indexWL)\n",
    "print(\"Index For Abstracts (lemmatizer)\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))\n",
    "indexWL.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, все показатели оказались лучше для индекса, построенного по abstracts, чем по titiles, так как увеличивается вероятностью встретить одинаковые термы и в запросе, и в тексте. Если сравнивать индексы, при построении и поиске по которым использовался стеммер с теми, где использовался лемматизатор, видно, что результаты приблизительно одинаковые, поэтому для дальнейших экспериментов решено было использовать стеммер (он быстрее работает). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = indexWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, используя Grid Search, найдем оптимальные параметры поиска (вычисление занимает несколько минут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_by_fmeasure = (0, 0, 0)\n",
    "best_by_map10 = (0, 0, 0)\n",
    "\n",
    "for k1 in arange(1.2, 2.1, .1):\n",
    "    for b in arange(.0, 1.1, .1):\n",
    "        precision, recall, fmeasure, map10 = parse_search_eval(index, b=b, k1=k1)\n",
    "        if fmeasure > best_fmeasure[2]:\n",
    "            best_by_fmeasure = (precision, recall, fmeasure, map10, b, k1)\n",
    "\n",
    "        if map10 > best_map10[3]:\n",
    "            best_by_fmeasure = (precision, recall, fmeasure, map10, b, k1)\n",
    "            \n",
    "print(\"Best f-measure = {} at b = {}, k1 = {}\".format(best_by_fmeasure[2], best_by_fmeasure[4], best_by_fmeasure[5]))\n",
    "print(\"Best map10 = {} at b = {}, k1 = {}\".format(best_by_map10[3], best_by_fmeasure[4], best_by_fmeasure[5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Вывод про b и k1\n",
    "\n",
    "Попробуем заменить функцию вычисления IDF-составляющей, используя при этом значения b и k1, для которых было получено лучшее значение f-меры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_rsv_custom_idf(N, Nt, ftd, ftq, Ld, L, b, k1, k2):\n",
    "    idf = math.log(N / Nt)\n",
    "    tf = ftd * (k1 + 1) / (k1 * ((1 - b) + b * Ld / L) + ftd)\n",
    "    return idf * tf\n",
    "\n",
    "precision, recall, fmeasure, map10 = parse_search_eval(index, b=best_by_fmeasure[4], k1=best_by_fmeasure[5], rsvfunc=calc_rsv_custom_idf)\n",
    "print(\"Results:\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, данное изменение не привело к улучшению. Скорее всего потому, что стандартная формула несколько сглаживает используемой значение IDF.\n",
    "\n",
    "Далее, попробуем нормализовать RSV документа на сумму IDF термов запроса, которые в него входят."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision, recall, fmeasure, map10 = parse_search_eval(index, b=best_by_fmeasure[4], k1=best_by_fmeasure[5], norm_rsv=True)\n",
    "print(\"Results:\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация несколько ухудшила значение f-меры и сильно ухудшила значение MAP@10. Благодаря такому приему, должно было уменьшиться влияние частовстречающихся слов на полученный RSV, однако, скорее всего из-за того что стоп-слова были отфильтрованы, результаты только ухудшились."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
